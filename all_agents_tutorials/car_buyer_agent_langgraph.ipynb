{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Car Buyer AI Agent\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook presents an intelligent car-buying assistant using LangGraph and an LLM model. The system assists users in defining their car-buying needs, refines search filters, and retrieves relevant listings, providing a streamlined buying experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from typing import TypedDict, Dict, List, Any\n",
    "from langgraph.graph import StateGraph, END, START, MessagesState\n",
    "from langchain_openai import ChatOpenAI\n",
    "from IPython.display import display, Image\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "from langsmith import Client\n",
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai\n",
    "import openai\n",
    "import asyncio\n",
    "from importnb import Notebook\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# This import is required only for jupyter notebooks, since they have their own eventloop\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "with Notebook():\n",
    "    from scrapers.autotrader import AutotraderInterface, WebsiteInterface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!playwright install\n",
    "!patchright install chromium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"car_buyer_agent\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv('LANGCHAIN_API_KEY')\n",
    "\n",
    "GPT = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "langsmith_client = Client()\n",
    "openai_client = wrap_openai(openai.Client())\n",
    "\n",
    "# search = DuckDuckGoSearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    \"\"\"Represents the state of the car-buying process.\"\"\"\n",
    "    user_needs: str\n",
    "    web_interfaces: List[WebsiteInterface]\n",
    "    listings: List[Dict[str, str]]\n",
    "    selected_listing: Dict[str, str]\n",
    "    additional_info: Dict[str, str]\n",
    "    next_node: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "\n",
    "class NextStep(Enum):\n",
    "    ASK_USER_NEEDS = \"ask_user_needs\"\n",
    "    BUILD_FILTERS = \"build_filters\"\n",
    "    IRRELEVANT = \"irrelevant\"\n",
    "\n",
    "class UserNeeds(BaseModel):\n",
    "    user_needs: str\n",
    "    next_step: NextStep\n",
    "\n",
    "USER_NEEDS_GPT = ChatOpenAI(model=\"gpt-4o-mini\", response_format=UserNeeds)\n",
    "\n",
    "def ask_user_needs(state: State) -> State:\n",
    "    \"\"\"Ask user initial questions to define their needs for the car.\"\"\"\n",
    "    messages = state.get(\"messages\", [])    \n",
    "    if len(messages) == 0:\n",
    "        system_message = \"You are a car buying assistant. Your goal is to help the user find a car that meets their needs. Start by introducing yourself and asking about their requirements, such as intended usage (e.g., commuting, family trips), budget, size preferences, and any specific constraints or features they value. Use their responses to guide them toward the best options.\"\n",
    "    else:\n",
    "        system_message = \"Ask the user for any additional information that can help narrow down the search. If he asked any questions before, answer them before asking for more information. When answering, make sure to provide clear and concise information, with relevant examples.\"\n",
    "        \n",
    "    existing_needs = state.get(\"user_needs\", \"\")\n",
    "    if existing_needs:\n",
    "        system_message += f\" Here's what we know about the needs of the user so far:\\n\\n{existing_needs}\"\n",
    "\n",
    "    messages.append(SystemMessage(content=system_message))\n",
    "\n",
    "    # Get message from the LLM\n",
    "    response = GPT.invoke(messages).content\n",
    "    messages += [AIMessage(response)]\n",
    "    print(f\"\\033[92m{messages[-1].content}\\033[0m\")\n",
    "    \n",
    "    # User response\n",
    "    messages += [HumanMessage(input(response))]\n",
    "    print(f\"\\033[94m{messages[-1].content}\\033[0m\")\n",
    "    \n",
    "    summarization_messages = messages.copy()\n",
    "    \n",
    "    summarization_messages += [\n",
    "        SystemMessage(\n",
    "            \"Summarize the user's car-buying needs in clear and concise bullet points based on their input and any prior knowledge.\\n\"\n",
    "            \"Provide the next step, such as asking for more details or answer questions under ask_user_needs or going forward to build_filter:\\n\"\n",
    "            \"- Use 'ask_user_needs' if you need more information or if the user asked a question.\\n\"\n",
    "            \"- Use 'build_filters' if you have enough details to search for cars online.\\n\"\n",
    "            \"If the user's query is irrelevant to the matter at hand (buying a car), respond 'irrelevant'.\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    response = json.loads(USER_NEEDS_GPT.invoke(summarization_messages).content)\n",
    "\n",
    "    state[\"user_needs\"] = response[\"user_needs\"]\n",
    "    \n",
    "    messages += [AIMessage(\"I have summarized your car-buying needs as follows:\\n\" + state[\"user_needs\"])]\n",
    "    \n",
    "    print(f\"\\033[92m{messages[-1].content}\\033[0m\")\n",
    "    \n",
    "    state[\"next_node\"] = response[\"next_step\"]\n",
    "        \n",
    "    print(f\"\\nNext node: {state['next_node']}\")\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_filters(state: State) -> State:\n",
    "    \"\"\"Build and refine search filters based on user needs.\"\"\"\n",
    "\n",
    "    print(\"Building filters based on user needs...\")\n",
    "    \n",
    "    for interface in state[\"web_interfaces\"]:\n",
    "        filters_info = interface.get_filters_info()\n",
    "        \n",
    "        # TODO: Check if this website is useful to the user based on the filters\n",
    "        # If not continue to the next interface\n",
    "        \n",
    "        # If the website is useful, use LLM to setup the filters based on user needs\n",
    "        \n",
    "        # Define system instructions with filters information\n",
    "        system_message = SystemMessage(filters_info + \"\\n\\n\" + \"User needs:\\n\" + state[\"user_needs\"])\n",
    "\n",
    "        # Use the LLM to process the user's needs and set the filters\n",
    "        try:\n",
    "            result = GPT.invoke([system_message])\n",
    "            llm_response = result.content.strip()\n",
    "\n",
    "            # Validate and set the filters for the interface\n",
    "            interface.set_filters_from_llm_response(llm_response)\n",
    "            print(f\"\\nSuccessfully set filters for: {interface.base_url}\")\n",
    "            print(f\"Updated URL: {interface.url}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Failed to set filters for {interface.base_url}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing filters for {interface.base_url}: {e}\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_listings_from_sources(web_interfaces: List[WebsiteInterface]) -> List[Dict[str, str]]:\n",
    "    \"\"\"Simulate retrieval of car listings from LaCentrale and mobile.de based on filters.\n",
    "    \n",
    "    Args:\n",
    "        filters (dict): Dictionary containing search filters (e.g., budget, fuel type).\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of dictionaries, each representing a car listing.\n",
    "    \"\"\"\n",
    "    listings = []\n",
    "    for interface in web_interfaces:\n",
    "        listings += await interface.crawl()\n",
    "        \n",
    "    return listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Optional\n",
    "\n",
    "class UserResponse(BaseModel):\n",
    "    action: Literal['select_listing', 'refine_search', 'end_conversation']\n",
    "    listing_id: Optional[str]\n",
    "\n",
    "CLASSIFIER_GPT = ChatOpenAI(model=\"gpt-4o-mini\", response_format=UserResponse)\n",
    "\n",
    "def search_listings(state: State) -> State:\n",
    "    \"\"\"Search for cars on LaCentrale and mobile.de based on filters.\"\"\"\n",
    "    \"\"\"Display the first listings for the user to view.\"\"\"\n",
    "    \"\"\"Synchronous wrapper for search_listings.\"\"\"\n",
    "\n",
    "    print(\"Searching for listings based on user needs...\")\n",
    "    state[\"messages\"] += [SystemMessage(\"Searching for listings based on user needs...\")]\n",
    "\n",
    "    async def _search_listings():\n",
    "        return await fetch_listings_from_sources(state[\"web_interfaces\"])\n",
    "    \n",
    "    listings = asyncio.run(_search_listings())\n",
    "    state[\"listings\"] = listings\n",
    "    \n",
    "    print(f\"Successfully fetched {len(listings)} listings from the sources.\")\n",
    "    \n",
    "    AI_message = \"\"\n",
    "    \n",
    "    # Display the first few listings for the user to view\n",
    "    AI_message += \"Here are recent listings that match your requirements:\\n\"\n",
    "    for i, listing in enumerate(state[\"listings\"][:5], 1):\n",
    "        AI_message += f\"{i}.\\n\"\n",
    "        for key, value in listing.items():\n",
    "            formatted_key = key.replace(\"_\", \" \").capitalize()\n",
    "            AI_message += f\"   {formatted_key}: {value}\\n\"\n",
    "        AI_message += \"\\n\"  # Add an extra line for readability\n",
    "    \n",
    "    user_prompt = \"Would you like to view more details about a specific listing, or refine your search (Write END to finish this conversation) ?\"\n",
    "    AI_message += user_prompt\n",
    "        \n",
    "    state[\"messages\"].append(AIMessage(AI_message))\n",
    "    print(f\"\\033[92m{state['messages'][-1].content}\\033[0m\")\n",
    "    state[\"messages\"].append(HumanMessage(input(user_prompt)))\n",
    "    print(f\"\\033[94m{state['messages'][-1].content}\\033[0m\")\n",
    "       \n",
    "    response = json.loads(CLASSIFIER_GPT.invoke(state[\"messages\"]).content)\n",
    "    \n",
    "    print(response)\n",
    "\n",
    "    if response[\"action\"] == \"select_listing\":\n",
    "        state[\"next_node\"] = \"fetch_additional_info\"\n",
    "        selected_listing_id = response[\"listing_id\"]\n",
    "        for i, listing in enumerate(state[\"listings\"][:5], 1):\n",
    "            if selected_listing_id in listing[\"id\"]:\n",
    "                state[\"selected_listing\"] = listing\n",
    "                break\n",
    "    elif response[\"action\"] == \"refine_search\":\n",
    "        state[\"next_node\"] = \"ask_user_needs\"\n",
    "    else:\n",
    "        state[\"next_node\"] = END\n",
    "        \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "\n",
    "duckduckgo_search = DuckDuckGoSearchResults(max_results=3)\n",
    "\n",
    "def fetch_additional_info(state: State) -> State:\n",
    "    \"\"\"Fetch more details about the selected car listing.\"\"\"\n",
    "    listing = state[\"selected_listing\"]\n",
    "    car_name = listing[\"title\"]\n",
    "\n",
    "    queries = [f\"{car_name} common issues\", f\"{car_name} problem\", f\"{car_name} reliability\"]\n",
    "    context = \"\"\n",
    "    for query in queries:\n",
    "        search_results = duckduckgo_search.invoke(query)\n",
    "        formatted_results = f\"QUERY: {query}\\n\\n{search_results}\\n-------------------\\n\"\n",
    "        context += formatted_results\n",
    "\n",
    "    prompt = SystemMessage(\n",
    "        f\"Provide additional information about this car: {listing['title']}, \"\n",
    "        f\"including engine specifications, common issues with this model, and market value.\"\n",
    "        f\"Here is additioanl context to help you provide the information:\\n\\n{context}\"\n",
    "        f\"Here are the user needs, give some insights about the car based on the user needs:\\n\\n{state['user_needs']}\"\n",
    "    )\n",
    "    \n",
    "    result = GPT.invoke([prompt])\n",
    "    \n",
    "    listing[\"additional_info\"] = result.content\n",
    "    \n",
    "    print(f\"\\033[92mHere is additional information about the selected car:\\n{listing['additional_info']}\\n\\033[0m\")\n",
    "    \n",
    "    user_prompt = \"Would you like to view more details about another listing, or refine your search (Write END to finish this conversation) ?\"\n",
    "    state[\"messages\"] += [SystemMessage(user_prompt)]\n",
    "    state[\"messages\"] += [HumanMessage(input(user_prompt))]\n",
    "    print(f\"\\033[94m{state['messages'][-1].content}\\033[0m\")\n",
    "    \n",
    "    response = json.loads(CLASSIFIER_GPT.invoke(state[\"messages\"]).content)\n",
    "\n",
    "    if response[\"action\"] == \"select_listing\":\n",
    "        state[\"next_node\"] = \"fetch_additional_info\"\n",
    "        selected_listing_id = response[\"listing_id\"]\n",
    "        for i, listing in enumerate(state[\"listings\"][:5], 1):\n",
    "            if selected_listing_id in listing[\"id\"]:\n",
    "                state[\"selected_listing\"] = listing\n",
    "                break\n",
    "    elif response[\"action\"] == \"refine_search\":\n",
    "        state[\"next_node\"] = \"ask_user_needs\"\n",
    "    else:\n",
    "        state[\"next_node\"] = END\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StateGraph\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Define the nodes in the graph\n",
    "workflow.add_node(\"ask_user_needs\", ask_user_needs)\n",
    "workflow.add_node(\"build_filters\", build_filters)\n",
    "workflow.add_node(\"search_listings\", search_listings)\n",
    "workflow.add_node(\"fetch_additional_info\", fetch_additional_info)\n",
    "workflow.add_node(\"irrelevant\", lambda state: state)\n",
    "\n",
    "# Define edges\n",
    "workflow.add_conditional_edges(\"ask_user_needs\", lambda state: state[\"next_node\"], [\"build_filters\", \"ask_user_needs\", \"irrelevant\"])\n",
    "workflow.add_edge(\"build_filters\", \"search_listings\")\n",
    "workflow.add_conditional_edges(\"search_listings\", lambda state: state[\"next_node\"], [\"fetch_additional_info\", \"ask_user_needs\", END])\n",
    "workflow.add_edge(\"irrelevant\", END)\n",
    "\n",
    "# Set the entry and exit points\n",
    "workflow.set_entry_point(\"ask_user_needs\")\n",
    "workflow.add_conditional_edges(\"fetch_additional_info\", lambda state: state[\"next_node\"], [\"ask_user_needs\", \"fetch_additional_info\", END])\n",
    "\n",
    "\n",
    "# Compile the workflow\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify initial setup and function invocation\n",
    "def run_car_buyer_agent():\n",
    "    \"\"\"Run the car-buying assistant with LangGraph.\"\"\"\n",
    "        \n",
    "    messages = []\n",
    "    \n",
    "    initial_state = State(\n",
    "        user_needs={}, \n",
    "        web_interfaces=[AutotraderInterface()], \n",
    "        listings=[],\n",
    "        selected_listing={}, \n",
    "        additional_info={},\n",
    "        next_node=\"\",\n",
    "        messages=messages\n",
    "    )\n",
    "    result = app.invoke(initial_state)\n",
    "    return result\n",
    "\n",
    "# Execute the agent\n",
    "car_buyer_result = run_car_buyer_agent()\n",
    "\n",
    "# Print result for debugging purposes\n",
    "print(\"Car Buyer Result:\", car_buyer_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary of the final recommendation\n",
    "if \"selected_listing\" in car_buyer_result:\n",
    "    listing = car_buyer_result[\"selected_listing\"]\n",
    "    print(f\"\\nFinal Recommendation:\\n{listing['title']} - {listing['price']} - {listing['mileage']} km\")\n",
    "    print(\"Additional Information:\")\n",
    "    for key, value in car_buyer_result[\"additional_info\"].items():\n",
    "        print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"No car listing selected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
