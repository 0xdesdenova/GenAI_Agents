{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Car Buyer AI Agent\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook presents an intelligent car-buying assistant using LangGraph and an LLM model. The system assists users in defining their car-buying needs, refines search filters, and retrieves relevant listings, providing a streamlined buying experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from typing import TypedDict, Dict, List, Any\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from IPython.display import display, Image\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "from langsmith import Client\n",
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai\n",
    "import openai\n",
    "import asyncio\n",
    "from importnb import Notebook\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# This import is required only for jupyter notebooks, since they have their own eventloop\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "with Notebook():\n",
    "    from scrapers.autotrader import AutotraderInterface, WebsiteInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!playwright install\n",
    "!patchright install chromium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"car_buyer_agent\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv('LANGCHAIN_API_KEY')\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LangSmith client\n",
    "langsmith_client = Client()\n",
    "\n",
    "openai_client = wrap_openai(openai.Client())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    \"\"\"Represents the state of the car-buying process.\"\"\"\n",
    "    user_needs: str\n",
    "    web_interfaces: List[WebsiteInterface]\n",
    "    listings: List[Dict[str, str]]\n",
    "    selected_listing: Dict[str, str]\n",
    "    additional_info: Dict[str, str]\n",
    "    user_input: str\n",
    "    next_node: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response(response_content: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parse the response content from the model into a dictionary format.\n",
    "    \n",
    "    Args:\n",
    "        response_content (str): The text response from the model.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Parsed information as a dictionary.\n",
    "    \"\"\"\n",
    "    parsed_info = {}\n",
    "    # Simple parsing based on line-by-line key-value pairs (customize as needed)\n",
    "    lines = response_content.splitlines()\n",
    "    for line in lines:\n",
    "        if \":\" in line:\n",
    "            key, value = line.split(\":\", 1)\n",
    "            parsed_info[key.strip().lower()] = value.strip()\n",
    "    return parsed_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_user_needs(state: State) -> State:\n",
    "    \"\"\"Ask user initial questions to define their needs for the car.\"\"\"\n",
    "\n",
    "    # Check if we already have some user needs to preserve\n",
    "    existing_needs = state.get(\"user_needs\", \"\")\n",
    "    if existing_needs:\n",
    "        existing_needs_text = f\"Here's what I know about your needs so far:\\n{existing_needs}\\n\"\n",
    "    else:\n",
    "        existing_needs_text = \"I don't have any details about your needs yet.\"\n",
    "\n",
    "    # Generate the initial prompt for the LLM to ask the user about their car needs\n",
    "    initial_user_needs_prompt = (\n",
    "        f\"{existing_needs_text}\\n\\n\"\n",
    "        \"Please tell me more about your requirements to help find the best car for you. \"\n",
    "        \"Could you share details like budget, usage (e.g., daily commute, off-road), \"\n",
    "        \"preferred fuel type, and any must-have features?\"\n",
    "    )\n",
    "    \n",
    "    print(initial_user_needs_prompt)\n",
    "\n",
    "    user_input = input(\"Please enter your response: \")\n",
    "\n",
    "    # Construct a follow-up prompt to include both the user input and any existing needs\n",
    "    followup_prompt = (\n",
    "        \"Here's the information provided:\\n\\n\" +\n",
    "        (f\"Existing needs:\\n{existing_needs_text}\\n\\n\" if existing_needs else \"\") +\n",
    "        f\"User input: {user_input}\\n\\n\"\n",
    "        \"Based on all the provided information, please summarize the user's car-buying needs in one or a few clear, concise sentences.\"\n",
    "    )\n",
    "\n",
    "    # Send follow-up to the LLM to get a structured summary of user needs\n",
    "    followup_response = llm(followup_prompt)\n",
    "    state[\"user_needs\"] = followup_response.content.strip()  # Store as a single string\n",
    "    \n",
    "    print(\"I have summarized your car-buying needs as follows:\")\n",
    "    print(state[\"user_needs\"])\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_user_input(state: State) -> State:\n",
    "    \"\"\"Parse the user's input to determine the next action.\"\"\"\n",
    "    user_input = state.get(\"user_input\", \"\").lower()\n",
    "    if \"refine\" in user_input:\n",
    "        state[\"next_node\"] = \"build_filters\"\n",
    "    elif \"view\" in user_input:\n",
    "        state[\"next_node\"] = \"fetch_additional_info\"\n",
    "    elif \"select\" in user_input:\n",
    "        state[\"next_node\"] = END\n",
    "    else:\n",
    "        state[\"next_node\"] = \"ask_user_needs\"\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_filters(state: State) -> State:\n",
    "    \"\"\"Build and refine search filters based on user needs.\"\"\"\n",
    "    \n",
    "    for interface in state[\"web_interfaces\"]:\n",
    "        filters_info = interface.get_filters_info()\n",
    "        \n",
    "        # TODO: Check if this website is useful to the user based on the filters\n",
    "        # If not continue to the next interface\n",
    "        \n",
    "        # If the website is useful, use LLM to setup the filters based on user needs\n",
    "        \n",
    "        \n",
    "        # Define system instructions with filters information\n",
    "        system_message = SystemMessagePromptTemplate.from_template(\n",
    "            \"{filters_info}\"\n",
    "        )\n",
    "\n",
    "        # Define user input prompt\n",
    "        human_message = HumanMessagePromptTemplate.from_template(\n",
    "            \"User needs: {user_needs}\"\n",
    "        )\n",
    "\n",
    "        # Create a structured prompt template\n",
    "        prompt_template = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "\n",
    "        # Format the prompt with dynamic variables\n",
    "        prompt = prompt_template.format_messages(\n",
    "            user_needs=state[\"user_needs\"],\n",
    "            filters_info=filters_info,\n",
    "        )\n",
    "\n",
    "        # Use the LLM to process the user's needs and set the filters\n",
    "        try:\n",
    "            result = llm.invoke(prompt)\n",
    "            llm_response = result.content.strip()\n",
    "\n",
    "            # Validate and set the filters for the interface\n",
    "            interface.set_filters_from_llm_response(llm_response)\n",
    "            print(f\"Successfully set filters for: {interface.base_url}\")\n",
    "            print(f\"Updated URL: {interface.url}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Failed to set filters for {interface.base_url}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing filters for {interface.base_url}: {e}\")\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_listings_from_sources(web_interfaces: List[WebsiteInterface]) -> List[Dict[str, str]]:\n",
    "    \"\"\"Simulate retrieval of car listings from LaCentrale and mobile.de based on filters.\n",
    "    \n",
    "    Args:\n",
    "        filters (dict): Dictionary containing search filters (e.g., budget, fuel type).\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of dictionaries, each representing a car listing.\n",
    "    \"\"\"\n",
    "    listings = []\n",
    "    for interface in web_interfaces:\n",
    "        listings += await interface.crawl()\n",
    "        \n",
    "    return listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_listings(state: State) -> State:\n",
    "    \"\"\"Search for cars on LaCentrale and mobile.de based on filters.\"\"\"\n",
    "    \"\"\"Synchronous wrapper for search_listings.\"\"\"\n",
    "    async def _search_listings():\n",
    "        return await fetch_listings_from_sources(state[\"web_interfaces\"])\n",
    "    \n",
    "    listings = asyncio.run(_search_listings())\n",
    "    state[\"listings\"] = listings\n",
    "    \n",
    "    print(f\"Successfully fetched {len(listings)} listings from the sources.\")\n",
    "    \n",
    "    print(\"Here is what I found:\")\n",
    "    for i, listing in enumerate(listings):\n",
    "        print(f\"{i + 1}. {listing}\")\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_listings(state: State) -> State:\n",
    "    \"\"\"Display retrieved listings and ask the user for the next action.\"\"\"\n",
    "    print(\"Here are the cars that match your requirements:\")\n",
    "    for i, listing in enumerate(state[\"listings\"], 1):\n",
    "        print(f\"{i}.\")\n",
    "        for key, value in listing.items():\n",
    "            formatted_key = key.replace(\"_\", \" \").capitalize()\n",
    "            print(f\"   {formatted_key}: {value}\")\n",
    "        print()  # Add an extra line for readability\n",
    "    \n",
    "    # Prompt user for actions\n",
    "    state[\"user_input\"] = input(\n",
    "        \"Would you like to refine filters, view more details, or select a car? (refine/view/select): \"\n",
    "    ).strip().lower()\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_additional_info(state: State) -> State:\n",
    "    \"\"\"Fetch more details about the selected car listing.\"\"\"\n",
    "    listing_index = int(input(\"Enter the number of the listing you want to view details for: \")) - 1\n",
    "    state[\"selected_listing\"] = state[\"listings\"][listing_index]\n",
    "    listing = state[\"selected_listing\"]\n",
    "    prompt = (\n",
    "        f\"Provide additional information about this car: {listing['title']}, \"\n",
    "        f\"including engine specifications, common issues with this model, and market value.\"\n",
    "    )\n",
    "    result = llm(prompt)\n",
    "    state[\"additional_info\"] = parse_response(result.content)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StateGraph\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Define the nodes in the graph\n",
    "workflow.add_node(\"ask_user_needs\", ask_user_needs)\n",
    "workflow.add_node(\"build_filters\", build_filters)\n",
    "workflow.add_node(\"search_listings\", search_listings)\n",
    "workflow.add_node(\"display_listings\", display_listings)\n",
    "workflow.add_node(\"fetch_additional_info\", fetch_additional_info)\n",
    "workflow.add_node(\"parse_user_input\", parse_user_input)\n",
    "\n",
    "# Define edges\n",
    "workflow.add_edge(\"ask_user_needs\", \"build_filters\")\n",
    "workflow.add_edge(\"build_filters\", \"search_listings\")\n",
    "workflow.add_edge(\"search_listings\", \"display_listings\")\n",
    "workflow.add_edge(\"display_listings\", \"parse_user_input\")\n",
    "workflow.add_conditional_edges(\"parse_user_input\", lambda state: state[\"next_node\"])\n",
    "\n",
    "# Set the entry and exit points\n",
    "workflow.set_entry_point(\"ask_user_needs\")\n",
    "workflow.add_edge(\"fetch_additional_info\", END)\n",
    "\n",
    "# Compile the workflow\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify initial setup and function invocation\n",
    "def run_car_buyer_agent():\n",
    "    \"\"\"Run the car-buying assistant with LangGraph.\"\"\"\n",
    "    initial_state = State(\n",
    "        user_needs={}, \n",
    "        web_interfaces=[AutotraderInterface()], \n",
    "        listings=[], \n",
    "        selected_listing={}, \n",
    "        additional_info={},\n",
    "        user_input=\"\",\n",
    "        next_node=\"\"\n",
    "    )\n",
    "    result = app.invoke(initial_state)\n",
    "    return result\n",
    "\n",
    "# Execute the agent\n",
    "car_buyer_result = run_car_buyer_agent()\n",
    "\n",
    "# Print result for debugging purposes\n",
    "print(\"Car Buyer Result:\", car_buyer_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary of the final recommendation\n",
    "if \"selected_listing\" in car_buyer_result:\n",
    "    listing = car_buyer_result[\"selected_listing\"]\n",
    "    print(f\"\\nFinal Recommendation:\\n{listing['title']} - {listing['price']} - {listing['mileage']} km\")\n",
    "    print(\"Additional Information:\")\n",
    "    for key, value in car_buyer_result[\"additional_info\"].items():\n",
    "        print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"No car listing selected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
